# Answer

## 基本知识

### 指针和引用的区别
(1)指针：指针是一个变量，只不过这个变量存储的是一个地址，指向内存的一个存储单元；
而引用跟原来的变量实质上是同一个东西，只不过是原变量的一个别名而已。
(2)可以有const指针，但是没有const引用；
(3)指针可以有多级，但是引用只能是一级（int **p；合法 而 int &&a是不合法的）
(4)指针的值可以为空，但是引用的值不能为NULL，并且引用在定义的时候必须初始化；
(5)指针的值在初始化后可以改变，即指向其它的存储单元，而引用在进行初始化后就不会再改变了。
(6)"sizeof引用"得到的是所指向的变量(对象)的大小，而"sizeof指针"得到的是指针本身的大小；
(7)指针和引用的自增(++)运算意义不一样

(const char*) p
(char *) const p

### 虚函数是做什么的，底层实现原理是什么
要点是虚函数表和虚函数表指针的作用。C++中虚函数使用虚函数表和虚函数表指针实现，虚函数表是一个类的虚函数的地址表，用于索引类本身以及父类的虚函数的地址，
假如子类的虚函数重写了父类的虚函数，则对应在虚函数表中会把对应的虚函数替换为子类的虚函数的地址；虚函数表指针存在于每个对象中(通常出于效率考虑，
会放在对象的开始地址处)，它指向对象所在类的虚函数表的地址；在多继承环境下，会存在多个虚函数表指针，分别指向对应不同基类的虚函数表。

### 哈希表介绍下，哈希冲突怎么解决，STL中有哈希表吗，了解吗，线程安全吗
哈希函数：一般情况下，需要在关键字与它在表中的存储位置之间建立一个函数关系，以f(key)作为关键字为key的记录在表中的位置，通常称这个函数f(key)为哈希函数。

hash : 翻译为“散列”，就是把任意长度的输入，通过散列算法，变成固定长度的输出，该输出就是散列值。
这种转换是一种压缩映射，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一的确定输入值。
简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。

解决冲突的方法：
1. 开放定址法 ： 为产生冲突的地址H(key)求得一个地址序列
2. 链地址法   ：将所有哈希地址相同的记录都链接在同一个链表中
3. 再哈希法   ：产生冲突时，计算另一个哈希函数
4. 建立公共溢出区

stl中的实现叫做unordered_map，基于hash_table去实现的。
hash_map的查找速度比map要快，因为hash_map的查找速度与数据量大小无关，属于常数级别。map的查找速度是log(n)级别。
但是hash_map每次查找都需要执行hash函数，所以也比较耗时。

### 深度优先遍历和广度优先遍历区别，实现上的区别
广度优先遍历：从某个顶点出发，首先访问这个顶点，然后找出这个结点的所有未被访问的邻接点，访问完后再访问这些结点中第一个邻接点的所有结点，
            重复此方法，直到所有结点都被访问完为止。
深度优先遍历：从某个顶点出发，首先访问这个顶点，然后找出刚访问这个结点的第一个未被访问的邻结点，然后再以此邻结点为顶点，
            继续找它的下一个新的顶点进行访问，重复此步骤，直到所有结点都被访问完为止。
            要特别注意的是，二叉树的深度优先遍历比较特殊，可以细分为先序遍历、中序遍历、后序遍历。具体说明如下：
            先序遍历：对任一子树，先访问根，然后遍历其左子树，最后遍历其右子树。(根左右)
            中序遍历：对任一子树，先遍历其左子树，然后访问根，最后遍历其右子树。(左根右)
            后序遍历：对任一子树，先遍历其左子树，然后遍历其右子树，最后访问根。(左右根)

广度优先搜索算法：保留全部结点，占用空间大； 无回溯操作(即无入栈、出栈操作)，运行速度快。
深度优先搜素算法：不全部保留结点，占用空间少；有回溯操作(即有入栈、出栈操作)，运行速度慢。

通常 深度优先搜索法不全部保留结点，扩展完的结点从数据库中弹出删去，这样，一般在数据库中存储的结点数就是深度值，因此它占用空间较少。
所以，当搜索树的结点较多，用其它方法易产生内存溢出时，深度优先搜索不失为一种有效的求解方法。
广度优先搜索算法，一般需存储产生的所有结点，占用的存储空间要比深度优先搜索大得多，因此，程序设计中，必须考虑溢出和节省内存空间的问题。

### 左值、右值、std::move
左值: 表达式结束后依然存在的持久化对象
右值: 表达式结束时就不再存在的临时对象
所有的具名变量或者对象都是左值，而右值不具名

std::move 右值引用，用以引用一个右值，可以延长右值的生命周期。

### 线程安全问题出现的根本原因和解决方案
- 存在两个或者两个以上的线程共享一个资源
- 操作共享资源的代码有两句或者两句以上

- 同步代码块
    synchronized(锁){
        需要被同步的代码
    }
- 同步函数。
    修饰符 synchronized 返回值类型   函数名(形参列表..){

    }
注意：
   1. 同步代码块的锁可以是任意的对象。 同步函数的锁是固定的，非静态函数的锁对象是this对象。 静态函数的锁对象是class对象。
   2. 锁对象必须是多线程共享的对象，否则锁不住。
   3. 在同步代码块或者是同步函数中调用sleep方法是不会释放锁对象的，如果是调用了wait方法是会释放锁对象的。

### C++ define, define是在哪个阶段执行
编译的过程：(源程序) -> **预处理** -> (修改后的源程序)、**编译** -> (汇编程序)、**汇编** -> (可重定位的目标程序)、**连接** -> (可执行的目标程序)
预处理阶段需要做的事情：
(1) 文件包含
    可以把源程序中的#include 扩展为文件正文，即把包含的.h文件找到并展开到#include 所在处。
(2) 条件编译
    预处理器根据#if和#ifdef等编译命令及其后的条件，将源程序中的某部分包含进来或排除在外，通常把排除在外的语句转换成空行。
(3) 宏展开
    预处理器将源程序文件中出现的对宏的引用展开成相应的宏 定义，即本文所说的#define的功能，由预处理器来完成。
    经过预处理器处理的源程序与之前的源程序有所有不同，在这个阶段所进行的工作只是纯粹的替换与展开，没有任何计算功能，
    所以在学习#define命令时只要能真正理解这一点，这样才不会对此命令引起误解并误用。

### 死锁知道吗，什么情况下死锁，如何解决
1. 死锁原因
    　　死锁问题被认为是线程/进程间切换消耗系统性能的一种极端情况。在死锁时，线程/进程间相互等待资源，而又不释放自身的资源，导致无穷无尽的等待，其结果是任务永远无法执行完成。
    打个比方，假设有P1和P2两个进程，都需要A和B两个资源，现在P1持有A等待B资源，而P2持有B等待A资源，两个都等待另一个资源而不肯释放资源，就这样无限等待中，这就形成死锁，
    这也是死锁的一种情况。给死锁下个定义，如果一组进程中每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的。

2. 产生死锁必要条件
　　当然死锁的产生是必须要满足一些特定条件的：
　　1.互斥条件：某资源只能被一个进程使用，其他进程请求该资源时，只能等待，知道资源使用完毕后释放资源。
　　2.请求和保持条件：程序已经保持了至少一个资源，但是又提出了新要求，而这个资源被其他进程占用，自己占用资源却保持不放。
　　3.不剥夺条件：任何一个资源在没被该进程释放之前，任何其他进程都无法对他剥夺占用。
　　4.循环等待条件：当发生死锁时，所等待的进程必定会形成一个环路（类似于死循环），造成永久阻塞。

3. 处理死锁思路
　　预防死锁：破坏死锁的四个必要条件中的一个或多个来预防死锁。但不能破坏互斥条件，其他三个都可。
　　避免死锁：和预防死锁的区别就是，在资源动态分配过程中，用某种方式防止系统进入不安全的状态。
　　检测死锁：运行时出现死锁，能及时发现死锁，把程序解脱出来
　　解除死锁：发生死锁后，解脱进程，通常撤销进程，回收资源，再分配给正处于阻塞状态的进程。

### 进程线程的区别？什么时候会用多进程，什么时候会用多线程?
**根本区别：**进程是系统进行资源分配和调度的基本单元，线程是处理器任务调度和执行的基本单位
**资源开销：**每个进程都有独立的代码和数据空间（程序上下文），程序之间的切换会有较大的开销；线程可以看做轻量级的进程，同一类线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器（PC），线程之间切换的开销小。
**包含关系：**如果一个进程内有多个线程，则执行过程不是一条线的，而是多条线（线程）共同完成的；线程是进程的一部分，所以线程也被称为轻权进程或者轻量级进程。
**内存分配：**同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的
**影响关系：**一个进程崩溃后，在保护模式下不会对其他进程产生影响，但是一个线程崩溃整个进程都死掉。所以多进程要比多线程健壮。
**执行过程：**每个独立的进程有程序运行的入口、顺序执行序列和程序出口。但是线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制，两者均可并发执行

从调度开销和系统资源占用的角度回答：
多线程：IO密集型, IO处理 并且 大多时间在等待的时候最好用多线程
多进程：CPU密集型, 绝大多数时间在计算时最好用多进程

优点：进程在执行过程具有独立的内存单元，执行效率搞，有利于资源的管理和保护。
      线程之间能够共享全局变量，占用的系统资源比较少。
缺点：进程之间不共享全局变量，占用的系统资源比较大，进程开销资源较大
      线程之间共享全局变量，不利于资源管理和保护（抢占资源）

### 协程的概念
协程（Coroutines）是一种比线程更加轻量级的存在，正如一个进程可以拥有多个线程一样，一个线程可以拥有多个协程。
协程不是被操作系统内核所管理的，而是完全由程序所控制，也就是在用户态执行。这样带来的好处是性能大幅度的提升，因为不会像线程切换那样消耗资源。
协程不是进程也不是线程，而是一个特殊的函数，这个函数可以在某个地方挂起，并且可以重新在挂起处外继续运行。所以说，协程与进程、线程相比并不是一个维度的概念。
一个进程可以包含多个线程，一个线程也可以包含多个协程。简单来说，一个线程内可以由多个这样的特殊函数在运行，但是有一点必须明确的是，
一个线程的多个协程的运行是串行的。如果是多核CPU，多个进程或一个进程内的多个线程是可以并行运行的，但是一个线程内协程却绝对是串行的，
无论CPU有多少个核。毕竟协程虽然是一个特殊的函数，但仍然是一个函数。一个线程内可以运行多个函数，但这些函数都是串行运行的。
当一个协程运行时，其它协程必须挂起。

上下文切换
- 进程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户是无感知的。进程的切换内容包括页全局目录、内核栈、硬件上下文，切换内容保存在内存中。
    进程切换过程是由“用户态到内核态到用户态”的方式，切换效率低。
- 线程的切换者是操作系统，切换时机是根据操作系统自己的切换策略，用户无感知。线程的切换内容包括内核栈和硬件上下文。线程切换内容保存在内核栈中。
    线程切换过程是由“用户态到内核态到用户态”， 切换效率中等。
- 协程的切换者是用户（编程者或应用程序），切换时机是用户自己的程序所决定的。协程的切换内容是硬件上下文，切换内存保存在用户自己的变量（用户栈或堆）中。
    协程的切换过程只有用户态，即没有陷入内核态，因此切换效率高。

那和多线程比，协程有何优势？
    最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，
因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。
    第二大优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，
在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。
    因为协程是一个线程执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，
既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

### 切换进程和切换线程的代价
最终都会归属到上下文的切换。
进程切换分两步：
1.切换页目录以使用新的地址空间
2.切换内核栈和硬件上下文
对于linux来说，线程和进程的最大区别就在于地址空间，对于线程切换，第1步是不需要做的，第2是进程和线程切换都要做的。

切换的性能消耗：
1、线程上下文切换和进程上下文切换一个最主要的区别是线程的切换虚拟内存空间依然是相同的，但是进程切换是不同的。
这两种上下文切换的处理都是通过操作系统内核来完成的。内核的这种切换过程伴随的最显著的性能损耗是将寄存器中的内容切换出。
2、另外一个隐藏的损耗是上下文的切换会扰乱处理器的缓存机制。简单的说，一旦去切换上下文，处理器中所有已经缓存的内存地址一瞬间都作废了。
还有一个显著的区别是当你改变虚拟内存空间的时候，处理的页表缓冲（processor's Translation Lookaside Buffer (TLB)）或者相当的神马东西会被全部刷新，
这将导致内存的访问在一段时间内相当的低效。但是在线程的切换中，不会出现这个问题。

## 数据库

###  mysql更新一条数据需要刷新几次磁盘? 为什么?
redo log vs bin log
redo log: 如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程IO成本、查找成本都很高。
为了解决这个问题，MySQL的设计者使用了一种叫WAL的技术，WAL的全称是Write-Ahead Logging，关键点就是先写日志，再写磁盘。
当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。
InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。
InnoDB的redo log是固定大小的，比如可以配置为一组4个文件，每个文件的大小是1GB，那么总共就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写。

bin log: MySQL整体来看，其实就有两块:一块是Server层，它主要做的是MySQL功能层面的事情;还有一块是引擎层，负责存储相关的具体事宜。
上面我们聊到redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为 binlog(归档日志)。

区别：
redo log是InnoDB引擎特有的;bin log是MySQL的Server层实现的，所有引擎都可以使用。
redo log是物理日志，记录的是“在某个数据页上做了什么修改”;bin log是逻辑日志，记录的是这个语句的原始逻辑，比 如“给ID=2这一行的c字段加1 ”。
redo log是循环写的，空间固定会用完;bin log是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一 个，并不会覆盖以前的日志。

结合上面两种日志我们再来理解理解**一条update的执行过程:**
(1) 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器;
否则，需要先从磁盘读入内存，然后再返回。
(2) 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这 行新数据。
(3) 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。
(4) 执行器生成这个操作的binlog，并把binlog写入磁盘。
(5) 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交(commit)状态，更新完成。

### Mysql为什么使用b+树，而不是b树、AVL树或红黑树?

首先B树的所有节点都存储数据信息，而B+ 树的所有数据都存储在叶子节点
B+ 树是在B树的基础上的一种优化，使其更加适合外存储索引结构，InnoDB存储引擎及时B+树实现其索引结构
从B树结构图中可以看到每个节点中不仅包含数据的Key值，还有data值，而每一页的存储空间是有限的，
如果data数据较大时会导致每一个节点（也就是每一页）能存储的key的数量很小，当存储的数据量很大时同时会导致B树的深度很深，高度很高，
增大磁盘的IO次数，进而影响查询效率，在B+树中，所有数据节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储Key值信息，
这样可以大大增加每个节点存储的key值数量，降低B+树的高度.

1. B+Tree 扫库、表能力更强。
    如果要从 B-Tree 中扫描表数据的话，基本要把整棵树都要扫描一遍，因为每个节点都存在数据区。B+Tree 就不需要扫描整棵树，只需要扫描叶子节点就可以了。
2. B+Tree 的磁盘读写能力更强。
    B+Tree 的节点上是不保存数据的，那么它保存的关键字就更多，这样一次 IO 操作，加载的关键字就更多，所以它的磁盘读写能力更强。
3. B+Tree 的排序能力更强。
    B+Tree 的叶子节点天然就是顺序存放的 。 B+树叶子节点是顺序排列的，并且相邻节点具有顺序引用的关系
4. B+Tree 的查询效率更加稳定。
    比如我们从上图的 B-Tree 中查询一条 id 等于8的数据需要经过两次 IO 操作，查询一条 id 等于3的数据需要经过三次 IO 操作，
    而从上图的 B+Tree 中只有叶子节点才保存数据，所以查询任何数据都需要经过三次 IO 操作。 所以 B+Tree 的查询效率更加稳定。

### hash和b+树的使用场景?

关系型数据库中，索引大多采用B/B+树来作为存储结构，而全文搜索引擎的索引则主要采用hash的存储结构，这两种数据结构有什么区别？
如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。
如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据。如果是范围查询检索，这时候哈希索引就毫无用武之地了，
因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；同理，哈希索引也没办法利用索引完成排序，
以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；哈希索引也不支持多列联合索引的最左匹配规则；

B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题

先说Hash索引
在理想的情况下，key非常分散，不存在Hash碰撞的话，采用Hash索引可以唯一得确定一个key的位置，并且这个位置上就只有一个key，所以查找时间复杂度是O（1），
非常快，这是Hash索引的最主要优势。但是呢，Hash索引不是没有缺点，不存在Hash碰撞这是理想情况，通常情况下，同一个Hash值都不只有一个key，
也就是说你根据一个key找到了他的hash值位置之后，但是这个位置还有别的key，所以你还得从这个位置找到真正的key，至于怎么找，
这个和具体的hash碰撞处理方式有关，最常用的扩展链表法，就是在hash位置上放置链表，此时，就存在一个链表查询的过程，如果hash碰撞比较严重，
查询的时间复杂度就远不止O(1)，那么hash索引的优势就失去了。其次，Hash索引是不排序的，因此它只适用于等值查询，如果你要查询一定的范围内的数据，
那么hash索引是无能为力的，只能把数据挨个查，而不能仅仅是查询到头尾数据之后，从头读到位。并且，hash索引也无法根据索引完成排序，这也是它的不足之一。

再说B+数索引
B+树是一颗严格平衡搜索的树，从根节点到达每一个叶子节点的路径长度都是一样的，并且每个节点可以有多个孩子节点（高扇出），
所以可以进可能的把树的高度降到很低。这么做的好处是可以降低读取节点的次数，这就是的B+树非常适合做外部文件索引了。在外部文件索引中，
必须要读取到一个节点之后，才能知道它所有的孩子几点的位置，而读取一个节点对应一次IO，所以读取叶子节点的IO数就等于树的高度了，因此树的高度越低，
所需要的IO次数就越少。B+树是一颗搜索树，所有的数据都放在叶子节点上，并且这些数据是按顺序排列的。所以在范围查询中，只需要找到范围的上下界节点，
就可以得到整个范围内的数据，而且还有一个好处，由于这些数据都是排好序的，所以无需对数据进行再次排序。

总结：
1. Hash索引在不存在hash碰撞的情况下，之需一次读取，查询复杂度为O（1），比B+树快。
2. 但是Hash索引是无序的，所以只适用于等值查询，而不能用于范围查询，自然也不具备排序性。根据hash索引查询出来的数据，还有再次进行排序
3. B+树索引的复杂度等于树的高度，一般为3-5次IO。但是B+树叶子节点上的数据是排过序的，因此可以作用于范围查找，而且查询的数据是排过序的，无需再次排序。
对于像“SELECT xxx FROM TABLE1 WHERE xxx LIKE 'aaa%'”这样涉及到模糊匹配的查询，本质上也是范围查询。
4. 还有一点，数据库中的多列索引中，只能用B+树索引。数据在B+树的哪个结点上，只取决于最左边的列上的key，在结点中在一次按照第二列、第三列排序。
所以B+树索引有最左原则的特性。

## 网络
### TCP通讯处理粘包详解
一般所谓的TCP粘包是在一次接收数据不能完全地体现一个完整的消息数据。TCP通讯为何存在粘包呢？主要原因是TCP是以流的方式来处理数据，
再加上网络上MTU的往往小于在应用处理的消息数据，所以就会引发一次接收的数据无法满足消息的需要，导致粘包的存在。
处理粘包的唯一方法就是制定应用层的数据通讯协议，通过协议来规范现有接收的数据是否满足消息数据的需要。
在应用中处理粘包的基础方法主要有两种分别是以4节字描述消息大小或以结束符，实际上也有两者相结合的如HTTP,redis的通讯协议等。

### tcp三次握手，为什么不是两次，四次? 三次握手发的数据是什么?
1. **三次握手：**
第一次握手： A给B打电话说，你可以听到我说话吗？
第二次握手： B收到了A的信息，然后对A说： 我可以听得到你说话啊，你能听得到我说话吗？
第三次握手： A收到了B的信息，然后说可以的，我要给你发信息啦！

如果两次，那么B无法确定B的信息A是否能收到，所以如果B先说话，可能后面的A都收不到，会出现问题。
如果四次，那么就造成了浪费，因为在三次结束之后，就已经可以保证A可以给B发信息，A可以收到B的信息； B可以给A发信息，B可以收到A的信息。

2. **四次挥手：**
A: 喂，我不说了 (FIN)。A->FIN_WAIT1
B: 我知道了(ACK)。等下，上一句还没说完。Balabala…..（传输数据）。 B->CLOSE_WAIT | A->FIN_WAIT2
B: 好了，说完了，我也不说了（FIN）。 B->LAST_ACK
A: 我知道了（ACK）。 A->TIME_WAIT | B->CLOSED
A等待2MSL,保证B收到了消息,否则重说一次”我知道了”,A->CLOSED
这样，通过四次挥手，可以把该说的话都说完，并且A和B都知道自己没话说了，对方也没花说了，然后就挂掉电话（断开链接）了 。

1、建立连接协议（三次握手）
（1）客户端发送一个带SYN标志的TCP报文到服务器。这是三次握手过程中的报文1。

（2） 服务器端回应客户端的，这是三次握手中的第2个报文，这个报文同时带ACK标志和SYN标志。因此它表示对刚才客户端SYN报文的回应；
    同时又标志SYN给客户端，询问客户端是否准备好进行数据通讯。

（3） 客户必须再次回应服务段一个ACK报文，这是报文段3。

2、连接终止协议（四次握手）
由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。
收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。

（1） TCP客户端发送一个FIN，用来关闭客户到服务器的数据传送（报文段4）。
（2） 服务器收到这个FIN，它发回一个ACK，确认序号为收到的序号加1（报文段5）。和SYN一样，一个FIN将占用一个序号。
（3） 服务器关闭客户端的连接，发送一个FIN给客户端（报文段6）。
（4） 客户段发回ACK报文确认，并将确认序号设置为收到序号加1（报文段7）。

CLOSED: 这个没什么好说的了，表示初始状态。
LISTEN: 这个也是非常容易理解的一个状态，表示服务器端的某个SOCKET处于监听状态，可以接受连接了。
SYN_RCVD: 这个状态表示接受到了SYN报文，在正常情况下，这个状态是服务器端的SOCKET在建立TCP连接时的三次握手会话过程中的一个中间状态，
          很短暂，基本上用netstat你是很难看到这种状态的，除非你特意写了一个客户端测试程序，故意将三次TCP握手过程中最后一个ACK报文不予发送。
          因此这种状态时，当收到客户端的ACK报文后，它会进入到ESTABLISHED状态。
SYN_SENT: 这个状态与SYN_RCVD遥想呼应，当客户端SOCKET执行CONNECT连接时，它首先发送SYN报文，因此也随即它会进入到了SYN_SENT状态，
          并等待服务端的发送三次握手中的第2个报文。SYN_SENT状态表示客户端已发送SYN报文。
ESTABLISHED：这个容易理解了，表示连接已经建立了。
FIN_WAIT_1: 这个状态要好好解释一下，其实FIN_WAIT_1和FIN_WAIT_2状态的真正含义都是表示等待对方的FIN报文。
            而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，
            此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，
            都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。
FIN_WAIT_2：上面已经详细解释了这种状态，实际上FIN_WAIT_2状态下的SOCKET，表示半连接，也即有一方要求close连接，但另外还告诉对方，
            我暂时还有点数据需要传送给你，稍后再关闭连接。
TIME_WAIT: 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。
           如果FIN_WAIT_1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。

1、 为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？

这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。
但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,
也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。

2、 为什么TIME_WAIT状态还需要等2MSL后才能返回到CLOSED状态？

这是因为：虽然双方都同意关闭连接了，而且握手的4个报文也都协调和发送完毕，按理可以直接回到CLOSED状态（就好比从SYN_SEND状态到ESTABLISH状态那样）；
但是因为我们必须要假想网络是不可靠的，你无法保证你最后发送的ACK报文会一定被对方收到，因此对方处于LAST_ACK状态下的SOCKET可能会因为超时未收到ACK报文，
而重发FIN报文，所以这个TIME_WAIT状态的作用就是用来重发可能丢失的ACK报文，并保证于此。

### 出现大量time_wait怎么办

打开系统的TIMEWAIT重用和快速回收。

### TCP协议保证数据传输可靠性的方式主要有：

1. 检验和
在发送数据时，为了计算数据包的校验和。应该按如下步骤：
（1）把校验和字段置为0；
（2）把需要校验的数据看成以16位为单位的数字组成，依次进行二进制反码求和；
（3）把得到的结果存入校验和字段中。
在接收数据时，计算数据报的校验和相对简单，按如下步骤：
（1）把首部看成以16位为单位的数字组成，依次进行二进制反码求和，包括校验和字段；
（2）检查计算出的校验和的结果是否等于零（反码应为16个1）；
（3）如果等于零，说明被整除，校验是和正确。否则，校验和就是错误的，协议栈要抛弃这个数据包。
所谓的二进制反码求和，即为先进行二进制求和，然后对和取反。

2. 序列号
TCP将每个字节的数据都进行了编号，这就是序列号。
序列号的作用：
a、保证可靠性（当接收到的数据总少了某个序号的数据时，能马上知道）
b、保证数据的按序到达
c、提高效率，可实现多次发送，一次确认
d、去除重复数据
数据传输过程中的确认应答处理、重发控制以及重复控制等功能都可以通过序列号来实现

3. 确认应答机制（ACK）
　　TCP通过确认应答机制实现可靠的数据传输。在TCP的首部中有一个标志位——ACK，此标志位表示确认号是否有效。接收方对于按序到达的数据会进行确认，
  当标志位ACK=1时确认首部的确认字段有效。进行确认时，确认字段值表示这个值之前的数据都已经按序到达了。而发送方如果收到了已发送的数据的确认报文，
  则继续传输下一部分数据；而如果等待了一定时间还没有收到确认报文就会启动重传机制。

4. 超时重传机制
　　第一种情况：数据包丢失。当数据发出后在一定的时间内未收到接收方的确认，发送方就会进行重传（通常是在发出报文段后设定一个特定的时间间隔，到点了还没有收到应答则进行重传）。

　　第二种情况：确认包丢失。当接收方收到重复数据（通过序列号进行识别）的时就将其丢弃，重新发送ACK。

　　重传时间的确定：报文段发出到确认中间有一个报文段的往返时间RTT，显然超时重传时间RTO会略大于这个RTT，TCP会根据网络情况动态的计算RTT，
  即RTO是不断变化的。在Linux中，超时以500ms为单位进行控制，每次判定超时重发的超时时间都是500ms的整数倍。其规律为：如果重发一次仍得不到应答，
  就等待2*500ms后再进行重传，如果仍然得不到应答就等待4*500ms后重传，依次类推，以指数形式递增，重传次数累计到一定次数后，
  TCP认为网络或对端主机出现异常，就会强行关闭连接。

5. 连接管理机制
　　三次握手和四次挥手

6. 流量控制
　　接收端处理数据的速度是有限的，如果发送方发送数据的速度过快，导致接收端的缓冲区满，而发送方继续发送，就会造成丢包，
  继而引起丢包重传等一系列连锁反应。 因此TCP支持根据接收端的处理能力，来决定发送端的发送速度，这个机制叫做流量控制。
  在TCP报文段首部中有一个16位窗口长度，当接收端接收到发送方的数据后，在应答报文ACK中就将自身缓冲区的剩余大小，
  放入16窗口大小中。这个大小随数据传输情况而变，窗口越大，网络吞吐量越高，而一旦接收方发现自身的缓冲区快满了，
  就将窗口设置为更小的值通知发送方。如果缓冲区满，就将窗口置为0，发送方收到后就不再发送数据，但是需要定期发送一个窗口探测数据段，
  使接收端把窗口大小告诉发送端。
其过程如下：
注意：窗口大小不受16位窗口大小限制，在TCP首部40字节选项中还包含一个窗口扩大因子M，实际窗口大小是窗口字段的值左移M位。

7. 拥塞控制
　　流量控制解决了两台主机之间因传送速率而可能引起的丢包问题，在一方面保证了TCP数据传送的可靠性。然而如果网络非常拥堵，此时再发送数据就会加重网络负担，那么发送的数据段很可能超过了最大生存时间也没有到达接收方，就会产生丢包问题。
　　拥塞控制方法分为：慢开始、拥塞避免、快重传和快恢复。
